{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "verification_v1 = pd.read_csv(\"new data/CLD data - Verification_data V1.csv\")\n",
    "verification_v2 = pd.read_csv(\"new data/CLD data - Verification_data V2.csv\")\n",
    "node_mapping = pd.read_csv(\"new data/CLD data - Node Mapping.csv\")\n",
    "node_final = pd.read_csv(\"new data/CLD data - Node Final.csv\")\n",
    "\n",
    "def normalize_color(value):\n",
    "    try:\n",
    "        return str(int(float(value)))\n",
    "    except:\n",
    "        return \"0\"\n",
    "\n",
    "verification_v1['version'] = 'V1'\n",
    "verification_v2['version'] = 'V2'\n",
    "verification_combined = pd.concat([verification_v1, verification_v2], ignore_index=True)\n",
    "\n",
    "verification_combined['source_color'] = verification_combined['source_color'].fillna('0').astype(str).apply(normalize_color)\n",
    "verification_combined['target_color'] = verification_combined['target_color'].fillna('0').astype(str).apply(normalize_color)\n",
    "verification_combined['link_color'] = verification_combined['link_color'].fillna('0').astype(str).apply(normalize_color)\n",
    "\n",
    "verification_combined['participant_type'] = (\n",
    "    verification_combined['participant_type'].str.strip().str.lower().str.replace(' ', '_')\n",
    ")\n",
    "verification_combined['group'] = (\n",
    "    verification_combined['participant_type'] + \"_\" + verification_combined['participant_number'].astype(str)\n",
    ")\n",
    "\n",
    "column_mapping = {\n",
    "    'cause': 'source',\n",
    "    'effect': 'target',\n",
    "    'Master ID': 'source_master_id',\n",
    "    'Node ID': 'source_node_id',\n",
    "    'Master ID.1': 'target_master_id',\n",
    "    'Node ID.1': 'target_node_id',\n",
    "    'polarity': 'polarity',\n",
    "    'participant_number': 'participant_number',\n",
    "    'participant_type': 'participant_type',\n",
    "    'source_color': 'source_color',\n",
    "    'target_color': 'target_color',\n",
    "    'Comment': 'comment'\n",
    "}\n",
    "verification_combined.rename(columns=column_mapping, inplace=True)\n",
    "\n",
    "def map_comment_to_type(row):\n",
    "    if row['version'] == 'V1':\n",
    "        return 'O'\n",
    "    elif pd.isna(row['comment']) or row['comment'].strip() == '':\n",
    "        return 'K'\n",
    "    return ''.join(w.capitalize()[0] for w in row['comment'].split())\n",
    "\n",
    "verification_combined['types'] = verification_combined.apply(map_comment_to_type, axis=1)\n",
    "\n",
    "node_v1_index_map = node_mapping.set_index('Node ID')['Index'].to_dict()\n",
    "node_v2_index_map = node_mapping.set_index('Node ID.1')['Index'].to_dict()\n",
    "node_index_map = {**node_v1_index_map, **node_v2_index_map}\n",
    "node_final_master_map = node_final.set_index('Node ID')['Master ID'].to_dict()\n",
    "merged_node_index_map = {**node_index_map, **node_final_master_map}\n",
    "\n",
    "def map_node_id_to_index(node_id):\n",
    "    return str(merged_node_index_map.get(node_id, node_id))\n",
    "\n",
    "verification_combined['source_map_id'] = verification_combined['source_node_id'].apply(map_node_id_to_index)\n",
    "verification_combined['target_map_id'] = verification_combined['target_node_id'].apply(map_node_id_to_index)\n",
    "\n",
    "src_colors = verification_combined[['source_map_id', 'source_color', 'group', 'version']]\n",
    "tgt_colors = verification_combined[['target_map_id', 'target_color', 'group', 'version']]\n",
    "src_colors.columns = ['node_id', 'color', 'group', 'version']\n",
    "tgt_colors.columns = ['node_id', 'color', 'group', 'version']\n",
    "\n",
    "all_node_colors = pd.concat([src_colors, tgt_colors])\n",
    "all_node_colors = all_node_colors.dropna()\n",
    "all_node_colors['node_id'] = all_node_colors['node_id'].astype(str)\n",
    "all_node_colors['color'] = all_node_colors['color'].apply(normalize_color)\n",
    "\n",
    "color_lookup = {\n",
    "    (row['group'], row['version'], row['node_id']): row['color']\n",
    "    for _, row in all_node_colors.iterrows()\n",
    "}\n",
    "\n",
    "v2_to_v1_nodeid = node_mapping.set_index('Node ID.1')['Node ID'].dropna().astype(str).to_dict()\n",
    "node_label_map = node_final.set_index('Master ID')['Node Name'].to_dict()\n",
    "\n",
    "def build_colored_node(id_val, label, group, version_prefix):\n",
    "    id_str = str(id_val)\n",
    "    color = color_lookup.get((group, version_prefix, id_str), \"0\")\n",
    "    participant_type = group.split(\"_\")[0]\n",
    "\n",
    "    # Label fallback from verification_combined\n",
    "    if not label:\n",
    "        fallback_rows = verification_combined[\n",
    "            (verification_combined['version'] == version_prefix) & (\n",
    "                (verification_combined['source_map_id'].astype(str) == id_str) |\n",
    "                (verification_combined['target_map_id'].astype(str) == id_str)\n",
    "            ) & (verification_combined['group'] == group)\n",
    "        ]\n",
    "        if not fallback_rows.empty:\n",
    "            label = fallback_rows.iloc[0]['source'] if fallback_rows.iloc[0]['source_map_id'] == id_str else fallback_rows.iloc[0]['target']\n",
    "\n",
    "    history = [{\n",
    "        \"id\": id_str,\n",
    "        \"key\": id_str,\n",
    "        \"label\": label,\n",
    "        \"participant_type\": participant_type,\n",
    "        \"group\": group,\n",
    "        \"history\": []\n",
    "    }]\n",
    "\n",
    "    if version_prefix == \"V2\":\n",
    "        v1_node_id = v2_to_v1_nodeid.get(\"V2_\" + id_str)\n",
    "        if v1_node_id:\n",
    "            clean_id = str(v1_node_id).replace(\"V1_\", \"\").replace(\"V2_\", \"\")\n",
    "            v1_label_match = node_mapping[node_mapping['Node ID'].astype(str) == str(v1_node_id)]['Node Name V1'].values\n",
    "            v1_label = v1_label_match[0] if len(v1_label_match) > 0 else label\n",
    "            history = [{\n",
    "                \"id\": clean_id,\n",
    "                \"key\": clean_id,\n",
    "                \"label\": v1_label,\n",
    "                \"participant_type\": participant_type,\n",
    "                \"group\": group,\n",
    "                \"history\": []\n",
    "            }]\n",
    "\n",
    "\n",
    "    return {\n",
    "        \"data\": {\n",
    "            \"id\": id_str,\n",
    "            \"key\": f\"{version_prefix}_{id_str}\",\n",
    "            \"label\": label,\n",
    "            \"participant_type\": participant_type,\n",
    "            \"color\": color,\n",
    "            \"history\": history\n",
    "        },\n",
    "        \"classes\": \"\"\n",
    "    }\n",
    "\n",
    "grouped_all_data = {}\n",
    "\n",
    "for group in verification_combined['group'].unique():\n",
    "    gdf = verification_combined[verification_combined['group'] == group]\n",
    "    v1_edges, v2_edges = [], []\n",
    "    v1_nodes, v2_nodes = set(), set()\n",
    "\n",
    "    for _, row in gdf.iterrows():\n",
    "        edge = {\n",
    "            \"id\": f\"{row['source_map_id']}-{row['target_map_id']}\",\n",
    "            \"source\": str(row['source_map_id']),\n",
    "            \"target\": str(row['target_map_id']),\n",
    "            \"label\": \"+\" if row['polarity'] == \"positive\" else \"-\",\n",
    "            \"value\": 1 if row['polarity'] == \"positive\" else -1,\n",
    "            \"polarity\": row[\"polarity\"],\n",
    "            \"participant_type\": row[\"participant_type\"],\n",
    "            \"group\": group,\n",
    "            \"color\": row[\"link_color\"]\n",
    "        }\n",
    "        if row['version'] == 'V1':\n",
    "            v1_edges.append({\"data\": edge})\n",
    "            v1_nodes.update([row['source_map_id'], row['target_map_id']])\n",
    "        else:\n",
    "            v2_edges.append({\"data\": edge})\n",
    "            v2_nodes.update([row['source_map_id'], row['target_map_id']])\n",
    "\n",
    "    v1_node_objs = [\n",
    "        build_colored_node(\n",
    "            n,\n",
    "            node_mapping[node_mapping['Node ID'].astype(str) == str(n)]['Node Name V1'].values[0]\n",
    "            if not node_mapping[node_mapping['Node ID'].astype(str) == str(n)].empty else \"\",\n",
    "            group,\n",
    "            \"V1\"\n",
    "        )\n",
    "        for n in sorted(v1_nodes)\n",
    "    ]\n",
    "    # Start with V2 node IDs from actual links\n",
    "    all_v2_ids = set(v2_nodes)\n",
    "\n",
    "    # Also include V2 nodes that appear in verification_combined under this group\n",
    "    valid_group_v2_ids = verification_combined[\n",
    "        (verification_combined['version'] == 'V2') & (verification_combined['group'] == group)\n",
    "    ]['source_node_id'].astype(str).tolist() + \\\n",
    "    verification_combined[\n",
    "        (verification_combined['version'] == 'V2') & (verification_combined['group'] == group)\n",
    "    ]['target_node_id'].astype(str).tolist()\n",
    "\n",
    "    # Normalize and add from mapping if theyâ€™re linked to this group\n",
    "    mapping_v2_ids = node_mapping['Node ID.1'].dropna().astype(str).str.replace('V2_', '')\n",
    "    all_v2_ids.update(set(valid_group_v2_ids) & set(mapping_v2_ids))\n",
    "\n",
    "\n",
    "    v2_node_objs = [\n",
    "        build_colored_node(\n",
    "            n,\n",
    "            node_mapping[node_mapping['Node ID.1'] == \"V2_\" + n]['Node Name V2'].values[0]\n",
    "            if not node_mapping[node_mapping['Node ID.1'] == \"V2_\" + n].empty else \"\",\n",
    "            group,\n",
    "            \"V2\"\n",
    "        )\n",
    "        for n in sorted(all_v2_ids)\n",
    "    ]\n",
    "\n",
    "    grouped_all_data[group] = {\n",
    "        \"V1\": {\"nodes\": v1_node_objs, \"edges\": v1_edges},\n",
    "        \"final\": {\"nodes\": v2_node_objs, \"edges\": v2_edges}\n",
    "    }\n",
    "\n",
    "with open(\"new_data.js\", \"w\", encoding=\"utf-8\") as f:\n",
    "    f.write(\"const allCyDataSets = \" + json.dumps(grouped_all_data, indent=2) + \";\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
